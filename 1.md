大厂 AIGC 算法与后端面试问题大纲

以下大纲汇总了百度、阿里、腾讯、字节跳动、华为、微软中国等大厂招聘 AIGC 算法岗和后端/平台岗时常见的考查方向和典型问题。内容依据近期 AIGC 面试资料和公开资源整理，适用于 2025 年应聘相关岗位的同学参考。为了方便准备，按“算法岗位大纲”和“后端岗位大纲”分列要点，尽可能涵盖最新技术热点和基础知识。

算法/模型研发工程师面试大纲
1. 大模型基础概念与原理

基本术语与结构

token 的含义及分词方式
raw.githubusercontent.com
；LLM 的类型（基础模型、开源模型与闭源模型）和分类
raw.githubusercontent.com
；自回归语言模型、信息理论和 n‑gram 模型等基础概念
raw.githubusercontent.com
。

注意力机制原理、FFN 块公式及激活函数选择
raw.githubusercontent.com
。

出现“涌现能力”、混合专家（MoE）结构的作用
raw.githubusercontent.com
。

模型风险与偏见

LLM 中偏见形成的原因，幻觉（Hallucination）产生和缓解方法
raw.githubusercontent.com
。

大语言模型的应用风险、伦理考虑以及“两类错误”（虚假生成与不当拒答）
raw.githubusercontent.com
raw.githubusercontent.com
。

模型命名与规模

参数规模命名（7B/13B/540B 等）及“Decoder‑only”架构盛行的原因
raw.githubusercontent.com
。

前缀语言模型（Prefix LM）与 Causal LM 的区别，LLMs 复读机现象与缓解方法
raw.githubusercontent.com
。

大模型智能体与多模态

大模型智能体概念及典型框架；理解生成式模型与检索增强（RAG）结合的原理。

多模态模型（文本‑图像/视频/音频）融合机制，扩散模型和 Stable Diffusion 等生成模型的基础原理与局限。

2. 模型训练与微调

训练目标与优化

Decoder‑only、Encoder‑only、Encoder‑Decoder 模型的训练目标和差异
raw.githubusercontent.com
；优化算法选择及混合精度训练
raw.githubusercontent.com
。

影响模型训练的关键因素：学习率调度、梯度裁剪、正则化以及批量大小等。

微调技术与迁移方法

SFT/Instruction‑Tuning、RLHF 及 PEFT（LoRA、Adapter、Prefix/P‑Tuning）等微调方法；Probing 和 Prompt Tuning 在迁移学习中的作用
raw.githubusercontent.com
。

全参数微调对显存需求的计算方法以及监督微调后能力下降的原因与缓解
raw.githubusercontent.com
。

数据集构建与评估

构建大模型训练语料和领域数据集的方法
raw.githubusercontent.com
；评估指标（perplexity、BLEU/ROUGE、FID 等）和人类评价结合
raw.githubusercontent.com
。

模型适应性及领域模型继续预训练的策略
raw.githubusercontent.com
。

分布式训练与并行策略

分布式训练必要性及 AllReduce 操作
raw.githubusercontent.com
。

数据并行、模型并行、流水线并行及混合并行的原理与适用场景
raw.githubusercontent.com
。

参数/激活检查点、混合精度和 ZeRO/FSDP 等节省显存策略。

3. 推理加速与模型能力提升

幻觉缓解与能力优化

使用检索增强生成（RAG）、知识库检索与校验来提升事实准确性；采用提示工程、反馈学习来减少幻觉。

数学推理、代码生成等领域的能力限制及改进方向（符号推理、外部工具调用）。

推理框架与加速技术

大模型推理加速框架的种类，如 vLLM、LightLLM、TensorRT‑LLM、SGLang 等
raw.githubusercontent.com
；Flash‑Attention、Paged‑Attention、Ring‑Attention 等高效注意力机制
raw.githubusercontent.com
。

KV Cache 缓存、流式输出、多批处理 (batching) 的实现细节，MQA/GQA 等多查询注意力优化
raw.githubusercontent.com
。

模型量化（AWQ、GPTQ）、稀疏矩阵和张量并行等手段在推理阶段的应用。

4. 大模型安全与伦理

模型的有害性与偏见产生机理
raw.githubusercontent.com
；制定安全对齐策略、防止违规内容生成的方法。

处理超出领域或无意义提示的策略
raw.githubusercontent.com
；评估模型伦理风险的标准与法规合规要求。

5. 其他高频知识点与实操考察

基于示例解释注意力缩放 ($\sqrt{d_k}$)、残差连接、LayerNorm 等公式推导。

经典扩散模型原理及采样策略；编码/解码架构与位置编码方式。

多模态融合（CLIP、DALL·E）与跨模态检索。

日志与指标监控、调优提示词/参数、在真实业务中优化模型效果的案例分析。

后端/平台工程师面试大纲
1. 模型部署基础与硬件知识

低精度与显存管理

区分 FP32、FP16 和 INT8 等数值精度，在训练与推理阶段的优势与折衷
raw.githubusercontent.com
；使用混合精度减小显存并提高推理速度
raw.githubusercontent.com
。

GPU 显存占用与利用率的定义及神经网络显存组成（数据、模型参数、特征映射）
raw.githubusercontent.com
；通过合理 batch、大页缓存和显存复用来降低内存。

分析模型参数量、FLOPs 计算、异构计算和端侧静态/动态多 Batch 区别
raw.githubusercontent.com
。

推理性能因素

影响推理速度的因素：模型大小、输入尺寸、线程/并发数、内存带宽和 GPU 利用率
raw.githubusercontent.com
。

缓存模型到内存带来的好处；延迟与吞吐量权衡；Volatile‑GPU‑Util 指标含义
raw.githubusercontent.com
。

高效 CNN 架构设计经验、NVIDIA GPU 架构特点、端侧部署评估指标（精度/耗时/内存/功耗）
raw.githubusercontent.com
。

模型文件与格式

safetensors、GGUF、Diffusion/Diffusers 等模型文件格式和转换方式
raw.githubusercontent.com
。

硬件架构与平台

x86 与 ARM 在深度学习侧的区别，高性能与低功耗取舍
raw.githubusercontent.com
；端侧硬件平台构成（视频编解码、CPU/GPU、AI 协处理器、DSP、DDR 等）
raw.githubusercontent.com
。

主流端侧芯片（NVIDIA、寒武纪、昇腾等）
raw.githubusercontent.com
；NVLink 等高速互联、InfiniBand/RoCE 网络、CUDA‑Graph、RDMA 等并行通讯技术。

MPI/NCCL/gloo 等分布式通信库，All‑gather 和 Reduce‑scatter 操作以及 ZeRO/FSDP 等分布式优化策略
raw.githubusercontent.com
。

2. 模型压缩与加速技术

模型压缩方法

模型压缩的重要性：减小参数、降低计算和存储开销以便端侧部署
raw.githubusercontent.com
。

模型量化：使用 FP16、INT8 或 INT4 保存模型参数，分为在线量化与离线量化
raw.githubusercontent.com
；AWQ/GPTQ/NF4 等方案在大模型推理中的使用。

模型剪枝：按突触、神经元或权重矩阵粒度裁剪不重要连接，结合稀疏矩阵降低计算量
raw.githubusercontent.com
。

模型蒸馏：利用教师模型软标签训练学生模型，提高小模型性能
raw.githubusercontent.com
。

区分前端（训练阶段）与后端（部署阶段）压缩技术，了解稀疏模型与 group convolution 的作用
raw.githubusercontent.com
。

内存和加速技术

混合专家（MoE）、KV cache 管理、Page‑Attention/Page/Flash/Ring‑Attention 等技术用于降低显存和提高吞吐量
raw.githubusercontent.com
。

多批次调度、流式输出和 Model Offloading（权重卸载到 CPU/磁盘），应对长输入或多序列生成的显存压力
raw.githubusercontent.com
。

自动批处理与动态 Batch，在高并发下减少重复计算，提高模型服务 QPS。

模型服务评测指标（响应延迟、吞吐量、GPU 占用率等）及 evalscope 等评测工具
raw.githubusercontent.com
。

3. 推理框架与服务架构

容器与编译技术

使用 NVIDIA 容器镜像搭建推理环境、检查驱动和 CUDA/TensorRT 版本匹配
raw.githubusercontent.com
。

PyTorch JIT/TorchScript 概念，移动端常用开源框架（MNN、NCNN、MACE 等）及它们的加速原理和区别
raw.githubusercontent.com
。

Torch、torchvision、CUDA、cuDNN 之间的关系；端侧框架转换导致结果不一致或 GPU 反而比 CPU 慢时的解决策略
raw.githubusercontent.com
。

分布式训练/推理

AI 模型的分布式训练方式（数据并行、模型并行、流水线并行）和分布式推理方式（tensor/kv 并行）
raw.githubusercontent.com
。

张量并行 vs 流水线并行 vs 数据并行的区别；AllReduce/AllGather、ReduceScatter 的作用。md

MACE 与 NCNN 框架的特点、加速原理以及适用场景
raw.githubusercontent.com
。

ONNX & TensorRT

ONNX 模型转换与优化流程、onnxsim 的作用
raw.githubusercontent.com
；在 GPU 与 CPU 之间缓存 ONNX 模型的技巧
raw.githubusercontent.com
。

TensorRT 基本概念、trtexec 工具使用、模型转换与序列化，构建缓存机制
raw.githubusercontent.com
。

Triton Inference Server 架构与 python‑backend 自定义推理后端实现
raw.githubusercontent.com
。

大模型推理框架

vLLM 架构、推理服务与调度器，LightLLM 的 TokenAttention 和 Efficient Router 技术
raw.githubusercontent.com
。

Ollama、Open‑WebUI、SGLang、LMDeploy (TurboMind) 等推理框架的特点与适用场景
raw.githubusercontent.com
；SGLang 前后端启动、generate 阶段和 RadixAttention/Fast‑Constrained‑Decoding 技术
raw.githubusercontent.com
。

KTransformers、vLLM、TensorRT‑LLM、SGLang、LMDeploy、Ulysses 混合技术和 Megatron 等框架/库的优势与局限
raw.githubusercontent.com
。

4. 数据处理与多媒体管道

流媒体与视频分析

DeepStream SDK 功能：借助 GPU 加速实现多流视频分析，支持摄像头/文件/流媒体输入并集成深度学习模型
raw.githubusercontent.com
；适用于智能城市、零售和工业场景
raw.githubusercontent.com
。

流媒体协议：RTP、RTCP、RTSP、WebRTC 等常见协议及适用场景
raw.githubusercontent.com
。

使用 OpenCV、FFmpeg、Gstreamer 拉取视频流并预处理；H.264/265 编解码、YUV 格式和 Base64 编码原理
raw.githubusercontent.com
。

Zigzag（Zig‑Zag）扫描在图像编码中的作用
raw.githubusercontent.com
。

5. 部署方案与性能评测

部署策略与技术栈

Page‑Attention/Flash‑Attention 技术用于管理 KV Cache，使显存按页分配并实现复制‑写策略
raw.githubusercontent.com
。

大模型流式输出管道设计，prefill 与 decode 阶段优化
raw.githubusercontent.com
；多查询和分块机制减少显存浪费。

vLLM 部署示例：参数配置、超长输入处理、token 长度计算、部署多 LoRA 模型
raw.githubusercontent.com
。

框架差异：Ollama、vLLM、LMDeploy、TensorRT‑LLM、SGLang 的对比及适用场景
raw.githubusercontent.com
。

评测与调优

大模型服务评测指标：延迟、吞吐、显存占用、GPU 利用率等
raw.githubusercontent.com
；使用 evalscope 等工具进行评测
raw.githubusercontent.com
。

Model Offloading 策略与 MCP（Model Context Protocol）服务框架
raw.githubusercontent.com
；模型 API 调用的示例和注意事项。

处理输入序列超出模型最大长度的方法，Ring‑Attention 等新技术
raw.githubusercontent.com
。

6. 自定义算子与框架扩展

自定义算子概念

在标准深度学习框架之外开发算子以实现特殊功能或优化性能
raw.githubusercontent.com
。适用于实现新激活函数、硬件加速、跨平台部署等场景
raw.githubusercontent.com
。

自定义算子的作用包括提升运行效率、扩展框架功能、适配特定硬件平台
raw.githubusercontent.com
。

实现流程

设计算子接口：定义输入输出形状与计算逻辑
raw.githubusercontent.com
。

编写底层实现：使用 C++/CUDA 等语言结合框架扩展 API
raw.githubusercontent.com
。

注册算子并测试，确保与标准算子数值一致；集成至部署引擎如 TensorRT 或 ONNX Runtime
raw.githubusercontent.com
。

不同框架中的自定义算子实现方式：PyTorch (autograd.Function/C++扩展)、TensorFlow (Custom Op API)、ONNX Runtime 扩展、TensorRT 插件等
raw.githubusercontent.com
。

7. 边‑云端协同与硬件加速

端侧部署与硬件平台

端侧 AI 部署关注精度、耗时、内存和功耗等指标
raw.githubusercontent.com
；理解为什么在端侧设备不使用传统图像算法
raw.githubusercontent.com
。

主要端侧硬件平台（NVIDIA、海思、寒武纪、昇腾、登临、联咏等）及其模块构成
raw.githubusercontent.com
raw.githubusercontent.com
。

XPU/MLU/MUSA 等新兴加速器特点；了解 diffusers 框架、Hopper GPU 架构、NVLink、NVIDIA GPU 发展历程及 Jetson 边端设备优势。

分布式通信与调度

MPI 并行计算、NCCL 技术与 Pytorch AllGather/ReduceScatter 的实现
raw.githubusercontent.com
。

FSDP、ZeRO、cuda‑graph、nccl‑test、RoCE 网络、InfiniBand 网卡、Ray、mpirun、nvidia‑smi、gloo 等工具和技术栈介绍。

RDMA 技术在大模型训练/推理中的作用。

视觉/计算机视觉相关面试大纲

这一部分着重归纳 AIGC 领域的视觉类问题，包括视频生成与理解、图像生成及控制技术，以及相关的训练与应用。考生应熟悉主流算法、模型架构和现实应用的挑战。

1. 视频生成与理解基础

视频任务种类：掌握视频理解的主要任务类别，包括视频分类、动作识别、文本‑视频检索、视频摘要、视频描述（captioning）、视频问答，以及各种时间维度任务（如视频摘要、精彩片段检测、动作定位、动作语义定位、密集视频描述）和时空维度任务（如多目标跟踪、行人再识别、显著性检测、视频实例分割）【382413383026198†L918-L925】。

生成框架与训练策略：理解文本‑视频、图像‑视频、视频‑视频三类生成框架的原理和细分应用，掌握数据增强策略（时间、空间、语义）、跨模态训练、长视频训练和有限数据训练等技术【1633255131073†L0-L16】。

数据与评估：了解视频生成与理解的数据工程和评估方法，包括训练数据预处理、提示增强、过滤长尾数据、跨文化评测以及视频生成评估指标（FVD 相对于 PSNR/SSIM 的优势），以及针对视频理解任务设计完整评测体系【594294120781368†L0-L26】。

典型视频生成模型：熟悉代表性的生成模型，如 Sora、Stable Video Diffusion（SVD）、CogVideoX、Wan2.1、HunyuanVideo、MAGI‑1 等，掌握其核心架构和创新点，例如世界模拟器理念、跨帧扩散模型、变形卷积结构、空间‑时间自注意力等【181356870569666†L0-L25】。

视频理解模型：了解 VideoLLaMB 的递归记忆桥接机制和 SceneTilling 算法、VideoGPT+ 的多采样策略、Sa2VA 融合 SAM‑2 与 LLaVA 的解耦设计以及 LLaVA‑NeXT 的零样本泛化能力等【287502302361032†L24-L76】。能够解释这些模型如何进行视频语义理解和跨模态推理。

视频编辑与修复：掌握基于扩散模型的视频编辑方法，包括文本驱动编辑、深度图/姿态图条件编辑、多条件控制（ControlVideo）、以及视频修复如旧影片上色、去噪等【787329922523045†L0-L23】。

人体视频生成专题：理解人体视频生成的定义和应用（电影、游戏、虚拟人、手语等），分析主要挑战如时间一致性、人体形变、复杂动作、环境交互和条件对齐；掌握解决时间一致性的技术（3D 卷积、光流约束、SMPL 模型、CLIP 指标），并了解数据集选择、评估指标和未来趋势【128860573057364†L30-L69】。

2. 图像生成与控制技术

扩散模型原理：理解扩散模型的基础原理（前向高斯加噪和反向去噪）、与 GAN/VAE 的区别、采样算法（DDPM、DDIM、DPM++ 等）和噪声调度策略，以及 Stable Diffusion 系列模型（1.5/2.1/3）的训练和推理流程、细节丢失问题和改进方向
raw.githubusercontent.com
。

LoRA 及其变种：掌握 LoRA 在 Stable Diffusion 微调中的使用和优势，了解多 LoRA 组合（合并、切换、叠加）、Hypernetwork、HyperDreamBooth、DiffLoRA、LoRA of Change，以及 DreamBooth、Textual Inversion、LoCon/LoHa/B‑LoRA 等不同微调技术的原理和适用场景【578466063676210†L0-L30】。

可控生成与 ControlNet：熟悉 ControlNet 系列及其扩展模块（Canny、深度、法线、姿态等控制条件），以及 IP‑Adapter、ControlNet++、ControlNext、Photomaker、InstantID、InstanceDiffusion、T2I‑Adapter、布局控制 (LayoutDM/LayoutDiffuse) 等众多控制方法；了解多模态控制模块（AnyScene、MIGC/MIGC++）、动态控制、MaxFusion、CreatiLayout、Ctrl‑X、OmniBooth、EasyPhoto、InstructPix2Pix 等技术的基本思想及应用场景【715858883442374†L0-L60】。

GAN 系列模型：回顾经典 GAN 及其改进（GAN、DCGAN、CGAN、WGAN、LSGAN、BigGAN），并了解在风格迁移（CycleGAN、StyleGAN）、图像编辑（Pix2Pix、GauGAN）、超分辨率（SRGAN、ESRGAN、Real‑ESRGAN、AuraSR）和人脸修复（GFPGAN）等任务中的典型模型，理解 GAN 与扩散模型各自的优劣【205170352714917†L25-L37】。

其他可控生成技术：掌握 AI 肖像一致性方法（PULID、FaceChain、InstantID、Easyphoto、Photomaker）、图像参考与编辑技术（LayerDiffusion、LuminaBrush、IC‑Light、IP‑Adapter、Concept Sliders、SUPIR、AnyText 等），以及虚拟换装/试衣模型（IDM_VTON、OOTDiffusion、AnyDoor）等可控生成技术，理解其主要流程和应用【793288778912623†L0-L44】。

3. 训练策略与应用实践

视频与图像模型的训练与微调：掌握不同生成框架（文本‑视频、图像‑视频、视频‑视频）的细分训练策略，包括数据增强（时间、空间、语义）、跨模态预训练、长视频训练技术、编辑模型训练方法，以及有限数据下的微调策略【1633255131073†L0-L16】。

评估体系与数据工程：理解在视频生成和理解任务中如何构建训练数据集、进行预处理与过滤，以及如何设计综合评测体系；掌握 FVD、FID、PSNR/SSIM 等指标的使用场景；了解针对长尾数据和跨文化场景的评测方法【594294120781368†L0-L26】。

将视觉与多模态结合：探索跨模态任务（如图文检索、视频问答）与视觉模型的结合方式，理解图像/视频特征如何与文本特征融合，涉及编码器共享、查询映射或融合等设计思想。

多模态面试大纲

该部分总结多模态模型和算法的核心概念、训练方法、模型架构及前沿技术。面试中常考察考生对多模态任务的原理理解、模型差异和应用场景。

1. 理论基础与概念

定义与方法：多模态研究使用多种媒体形式（文本、图像、音频、视频）共同建模，其常用方法包括数据融合（加权平均、贝叶斯估计、神经网络融合）、多模态深度学习（CNN、RNN、自动编码器等）和特征抽取技术（PCA、LDA、MDS），以及对多模态信息进行可视化和跨模态信息检索
raw.githubusercontent.com
。

预训练与微调差异：理解多模态预训练与下游任务微调的区别，掌握 Transformer 在多模态学习中的优势（自注意力机制能够统一处理不同模态）和多模态连接器（如 Query Transformer）的作用；熟悉参数高效微调方法和避免灾难性遗忘的策略
raw.githubusercontent.com
。

挑战与评估：认识多模态模型的挑战，如模态对齐困难、模态缺失、幻觉及跨模态偏见；了解评估基准和指标（CLIP Score、Recall@K 等），并掌握缓解幻觉的训练/推理策略。

2. 核心模型与算法

典型多模态模型：掌握 BLIP 系列模型的基本思想，理解 CLIP 的双流对比学习和为何 Stable Diffusion 选择 CLIP 而非 BLIP；熟悉 BLIP‑2 的创新（将视觉编码和语言模型分离，通过 Query Transformer 融合），LLaMA‑AdapterV2 的早融合方法，SAM 用于视觉语义分割，PaLM‑E 将语言与机器感知融合，CLIP 的跨模态对齐机制，GPT‑4V 的视觉推理能力，以及 ImageBind 将六个模态映射至统一嵌入空间等
raw.githubusercontent.com
。

多模态融合与小模型：理解多模态融合层的设计原则；掌握 Sora 等模型在视频生成方面的贡献；了解高效训练策略、3D‑LLM 架构及指令微调技术；比较 TinyGPT‑V 与 MiniGPT‑4 的差异，认识小型视觉‑语言模型（sVLM）的类别、优点与知识蒸馏方法，以及 Mamba 相比 Transformer 的效率提升和未来研究方向
raw.githubusercontent.com
。

Qwen‑VL 系列：掌握 Qwen‑VL 和 Qwen3‑VL 的核心创新，包括视觉编码器从第一代到第三代的演进（固定分辨率→动态分辨率→窗口注意力及三维 patch），M‑RoPE 用于统一文本‑图像‑视频的旋转位置编码，多阶段训练范式，绝对坐标与归一化坐标表示，动态 FPS 采样与三维分块，SFT 与 DPO 的结合，统一序列化、多语种支持、MRoPE‑Interleave 交错设计、DeepStack 用于 ViT 特征融合，T‑RoPE 时间戳对齐，3D 卷积 patch 嵌入以及嵌入图像/视频特征到文本序列的策略等
raw.githubusercontent.com
。

模态编码器：理解 CLIP 文本编码器的上下文长度限制（77 token）；比较 BERT 与 GPT‑3 在结构和用途上的差异（编码器/解码器架构）；理解 Vision Transformer (ViT) 与 MAE 的区别以及各自对图像特征提取的优劣；了解在多模态模型中编码器的作用以及 CLAP 利用对比学习学习音频表示的方法
raw.githubusercontent.com
。

训练与微调技术：熟悉大规模预训练的必要性和四种学习机制（监督、半监督、弱监督、自监督）；理解 Prompt Learning 与全参数微调的差异；掌握链式思维（CoT）推理、RLHF、上下文学习、LoRA 等 PEFT 方法的原理及调参技巧（矩阵初始化、秩 rank、alpha 参数选择），并了解多模态特征融合、掩码策略、视觉编码器选择、位置编码设计、下游任务适配、单模态与跨模态数据增强、多任务学习以及推理优化（压缩、量化、加速）的实践
raw.githubusercontent.com
。

主干骨干模型：理解 LLM Backbone 的概念，区分自动回归、自动编码、编码‑解码模型及 Flan‑T5、ChatGLM、LLaMA 等的差异；掌握 Backbone 处理多模态特征的方法，为什么 Transformer 架构适合不同模态，如何解决模态异构问题；了解参数规模对性能的影响、早融合与晚融合的优缺点；设计预训练任务实现跨模态对齐、缓解灾难性遗忘、推理与模型压缩、噪声与不平衡处理、可解释性提升以及大型多模态模型的评估指标
raw.githubusercontent.com
。

模态生成器：熟悉文本生成流程及解码策略（如贪婪解码、采样、束搜索）；掌握扩散图像生成模型的组件（文本编码器、扩散模型 UNet、VAE）、采样方法、后续解码（如 BPE）、视频生成器 Zeroscope 和音频生成器 AudioLDM 的原理和特点
raw.githubusercontent.com
。

前沿技术与趋势：了解多模态链式思维（MCoT）的概念、与单模态 CoT 的差异及其应用（如长视频分析、关键帧提取、幻觉抑制）；熟悉分阶段建模、异步建模和工具集成的推理机制；掌握通过多模态提示和专家工具调用实现跨模态推理的方法。了解检索增强生成（MARG）的不同版本，双流对比学习与生成式检索、RankGPT/TourRank 排序方法以及可视化 Token 压缩技术（LLaVolta、MustDrop）和 Augmented Multimodal Output 模块的工作原理
raw.githubusercontent.com
。此外，了解 Agents、LLaVA 系列衍生模型、多模态剪枝及文档解析等最新技术的发展脉络。

3. 面试思路与综合考点

多模态面试常聚焦于模型差异与应用场景。例如：对比 BLIP 与 CLIP 的训练目标和应用、说明如何实现不同模态之间的对齐、设计一套评估多模态模型的实验方案、讨论如何处理幻觉或模态缺失问题。

候选人可准备实际项目经历，如参与多模态检索/对话系统，说明使用的模型、数据集和遇到的问题，展示动手能力与问题分析能力。

关注前沿趋势，如多模态链式推理、检索增强生成、Agent 自动调用外部工具等，并思考这些技术的应用潜力和挑战。

使用建议

结合岗位定位学习：算法岗重点掌握大模型原理、训练与微调方法、推理加速和模型评估；后端岗需要熟悉模型部署和压缩、推理框架和系统设计、数据管道和硬件优化。

关注行业动态：及时跟进 2025 年新技术，如 RAG、AI Agent、开源大型模型、国产加速芯片和新型推理框架，理解它们的原理与应用场景。

实践与项目准备：准备面试时结合个人项目经历，针对上述大纲的各个知识点整理实例和解决方案，加强实操能力和问题分析能力。

备注：以上内容仅作为准备 AIGC 相关岗位面试的参考大纲。技术和公司要求会快速迭代，应结合最新资料和个人兴趣深入钻研。
